\addchap*{Abstract (English Version)}
\begin{otherlanguage}{english} %% switch babel language, ensure hyphenation is correct
With initial SAE level 4 systems publicly available, the proliferation of autonomous vehicles will continue to increase. Embedded within shared mobility solutions, this technical advancement will lead to a more sustainable, safe and comfortable future. Scaling these systems from small, well defined Operational Design Domains (ODD) to larger areas still remains a major challenge though, since the number and variety of complex scenes and scenarios increases drastically. While a single human driver rarely experiences corner cases, a robotic system running thousands of autonomous vehicles is frequently exposed to them.
Therefore, it is crucial to research on methodologies to detect corner cases for the situational awareness of the robotic system. Based on this, subsequent modules of the robotic system can utilize this awareness to handle corner cases.

While there is a thematic proximity to research issues related to verification and validation of autonomous vehicles, this work focuses on the methods for detecting and handling corner cases themselves as well as their interactions.
To link detection and subsequent modules within the robotic system it is necessary to utilize a common interface. Corner case descriptions for this purpose can be either categorical or robot-centric. While knowledge-driven categorial descriptions can help to understand corner cases, data-driven robot-centric ones are directly based on the current limits of the robotic system and therefore more actionable. The first step is to develop a machine-readable ontology for corner-cases that combines both approaches as an interface between detection and subsequent modules. Here, a focus will be on external, natural corner cases. Intentional attacks on the robotic system or internal system errors that lead to corner cases are neglected.
In a second step, it will be investigated how the multimodal environmental data provided by a typical sensor setup of an autonomous vehicle can be used to detect corner cases. An extensive research on state-of-the-art methods from the computer vision domain will provide the basis for this. Public data sets contain few corner cases, dashcam footage is based solely on imagery, and recreating and manually recording corner cases is often impossible. Therefore, this research will focus on simulation environments. Finally, it will be investigated how the subsequent planning module of a robotic system can utilize the output of the detection module. The primary focus will be on informed machine learning, which is able to incorporate a wide variety of knowledge representations into neural networks.

\end{otherlanguage}

\addchap*{Abstract (German Version)}
\begin{otherlanguage}{ngerman} %% switch babel language, ensure hyphenation is correct
Blubber
\end{otherlanguage}
